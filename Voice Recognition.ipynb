{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the folder structure. It might already be there, and that's fine\n",
    "from os import makedirs\n",
    "\n",
    "makedirs(\"data/sentences\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "# add -d to only output directories\n",
    "tree . -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a dataset made of sentences\n",
    "# found in moview reviews. The sentences\n",
    "# need to be at least 3 seconds long when\n",
    "# being read out loud. The sentences are\n",
    "# packed in tarball gunzip archive as two\n",
    "# files.\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "urlretrieve(\"http://www.cs.cornell.edu/people/pabo/movie-review-data/rotten_imdb.tar.gz\",\n",
    "            \"data/sentences/sentences.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "ls -al data/sentences/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the files from the tarball archive.\n",
    "# We use the \"with\" syntax so that the file\n",
    "# handler is closed automatically afterwards.\n",
    "import tarfile\n",
    "\n",
    "with tarfile.open(\"data/sentences/sentences.tar.gz\") as tar:\n",
    "    tar.extractall(\"data/sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "# You can now see two files that have the extension 5000\n",
    "# That's how many samples are there. In total 10.000\n",
    "ls -al data/sentences/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "# Sentences are one per line. here are the first 3\n",
    "head -n3 data/sentences/quote.tok.gt9.5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the sentences from both files and create a list of sentences.\n",
    "\n",
    "sentences = []\n",
    "with open(\"data/sentences/plot.tok.gt9.5000\", \"r\", encoding = \"ISO-8859-1\") as fp:\n",
    "    sentences.extend(fp.read().split(\"\\n\")[0:5000])\n",
    "with open(\"data/sentences/quote.tok.gt9.5000\", \"r\", encoding = \"ISO-8859-1\") as fp:\n",
    "    sentences.extend(fp.read().split(\"\\n\")[0:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First few sentences\n",
    "sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makedirs(\"data/mp3\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# This is a client object that allows us to communicate with the AWS service\n",
    "# I am running on the AWS infrastructure, so I don't have to provide other details.\n",
    "# In practice, depending on where you run your script, you might need to provide\n",
    "# additional information (like credentials, regions etc.)\n",
    "# If for some reason, client does not get initiated, it will remain set to None\n",
    "client = None\n",
    "try:\n",
    "    client = boto3.client(\"polly\", region_name=\"us-east-1\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Define a list with the voices in AWS Polly\n",
    "voices = [\"Ivy\", \"Joanna\", \"Joey\", \"Justin\", \"Kendra\", \"Kimberly\", \"Matthew\", \"Salli\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We randomly pick a voice to say the sentence out loud.\n",
    "# closing is a convenience stream utility so that we\n",
    "# don't have to close the stream manually.\n",
    "# io allows us to work with stream of data coming from Polly.\n",
    "import random\n",
    "from contextlib import closing\n",
    "import io\n",
    "\n",
    "# We need an id in the form of a counter for the sentences sequence,\n",
    "# and the sentence itself\n",
    "def process_input(i, sentence):\n",
    "    # Get a random voice\n",
    "    voice = random.choice(voices)\n",
    "\n",
    "    # The path to the mp3 we are about to download and write to disk\n",
    "    # The voice that was used is part of the file name. We can use it for\n",
    "    # labeling our training data later one\n",
    "    file_mask = \"data/mp3/sample-{:05}-{}.mp3\".format(i, voice)\n",
    "\n",
    "    # Ask Polly to do its magic\n",
    "    response = client.synthesize_speech(\n",
    "        OutputFormat=\"mp3\",\n",
    "        Text=sentence,\n",
    "        TextType=\"text\",\n",
    "        VoiceId=voice\n",
    "    )\n",
    "    # Get the bytes stream containing the mp3\n",
    "    with closing(response[\"AudioStream\"]) as stream:\n",
    "        # Write the stream to a bytes buffer in memory\n",
    "        with io.BytesIO() as buffer:\n",
    "            # If we fail, for whatever reason (Eg: AWS is throttling us), we skip the file\n",
    "            try:\n",
    "                buffer.write(stream.read())\n",
    "                buffer.seek(0)\n",
    "                # Finally write the mp3 to disk\n",
    "                with open(file_mask, \"wb\") as out:\n",
    "                    out.write(buffer.read())\n",
    "            except _:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# This takes a few seconds so it's useful to time it\n",
    "\n",
    "# To move things faster we'll do \"multi threading\"\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "# We launch a maximum of 10 functions at a time for each sentence in the set\n",
    "# For the purpose of demonstrating we're only going to use 20 sentences\n",
    "with ThreadPool(processes=10) as pool:\n",
    "    # This if is here for the case where you don't have or don't want to use AWS,\n",
    "    # should that be the case, you can create a folder data/mp3 and copy there the\n",
    "    # contents of mp3, which represent the 10.000 mp3 from Polly readily available\n",
    "    if client:\n",
    "        pool.starmap(process_input, enumerate(sentences[:200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%sh\n",
    "# Show a few mp3 files\n",
    "ls -al data/mp3/ | head -6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# create a list of the mp3 files we have. We look at all the entities in the data.mp3 folder,\n",
    "# but keep only the files\n",
    "mp3_files = sorted([f for f in listdir(\"data/mp3\") if isfile(join(\"data/mp3\", f))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(filename=f\"data/mp3/{mp3_files[3]}\", autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only want to use a couple of seconds, so we trim the recordings\n",
    "sample_start = random.randint(500, 1000)\n",
    "sample_finish = sample_start + 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makedirs(\"data/wav\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "# We need an id in the form of a counter for the sentences sequence,\n",
    "# and the sentence itself\n",
    "def process_mp3(_, mp3):\n",
    "    # To create spectrograms, we need to have waveform files, which is just another audio format\n",
    "    # We use a library for this conversion\n",
    "    sound = AudioSegment.from_mp3(f\"data/mp3/{mp3}\")[sample_start:sample_finish]\n",
    "    sound.export(f\"data/wav/{mp3[:-3]}wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# This takes a few seconds so it's useful to time it\n",
    "\n",
    "# We launch a maximum of 32 functions at a time\n",
    "# For the purpose of demonstrating we're only going to use a limited number of mp3\n",
    "with ThreadPool(processes=32) as pool:\n",
    "    pool.starmap(process_mp3, enumerate(mp3_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%sh\n",
    "# Show a few waveform files\n",
    "ls -al data/wav/ | head -6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_files = sorted([f for f in listdir(\"data/wav/\") if isfile(join(\"data/wav/\", f))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(filename=f\"data/wav/{wav_files[3]}\", autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use(\"agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import wave\n",
    "\n",
    "# function for generating a spectrogram image file from a waveform audio file\n",
    "def graph_spectrogram(wav_file):\n",
    "    wav = wave.open(f\"data/wav/{wav_file}\", \"r\")\n",
    "    frames = wav.readframes(-1)\n",
    "    sound_info = np.frombuffer(frames, \"int16\")\n",
    "    frame_rate = wav.getframerate()\n",
    "    wav.close()\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches((1.4, 1.4))\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    plt.set_cmap(\"hot\")\n",
    "    plt.specgram(sound_info, Fs=frame_rate)\n",
    "    plt.savefig(f\"data/spectrograms/{wav_file[:-3]}png\", format=\"png\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makedirs(\"data/spectrograms\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# This takes a few seconds so it's useful to time it\n",
    "# This is better if it happens sequentially, because of the amount of memory used by the plotting library\n",
    "\n",
    "# For the purpose of demonstrating we're only going to use a limited number of wav\n",
    "for wav_file in wav_files:\n",
    "    graph_spectrogram(wav_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%sh\n",
    "# Show a few mp3 files\n",
    "ls -al data/spectrograms/ | head -6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms = sorted([join(\"data/spectrograms/\", f) for f in listdir(\"data/spectrograms/\") if isfile(join(\"data/spectrograms/\", f))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(filename = spectrograms[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"spectrogram\": spectrograms})\n",
    "df[\"label\"] = df.spectrogram.str.extract(\"sample-\\\\d+-(\\\\w+)\\\\.png\", expand=False).apply(lambda x: voices.index(x))\n",
    "df[\"voice\"] = df.spectrogram.str.extract('sample-\\\\d+-(\\\\w+)\\\\.png', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.groupby(\"voice\").apply(lambda x: x.sample(frac=.8)).reset_index(0, drop=True)\n",
    "validation = df.loc[np.logical_not(df.index.isin(train.index)), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby(\"voice\")[\"label\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation.groupby(\"voice\")[\"label\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mxnet as mx\n",
    "\n",
    "def transform(row):\n",
    "    img = cv2.imread(row[\"spectrogram\"])\n",
    "    img = mx.nd.array(img)\n",
    "    img = img.astype(np.float32)\n",
    "    img = mx.nd.transpose(img, (2, 0, 1))\n",
    "    img = img / 255\n",
    "    label = np.float32(row[\"label\"])\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_nd = [transform(row) for _, row in train.iterrows()]\n",
    "validation_nd = [transform(row) for _, row in validation.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nd[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon.data import DataLoader\n",
    "\n",
    "train_data = DataLoader(train_nd, batch_size, shuffle=True)\n",
    "validation_data = DataLoader(validation_nd, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon.nn import Sequential, Conv2D, MaxPool2D, Dropout, Flatten, Dense\n",
    "\n",
    "net = Sequential()\n",
    "with net.name_scope():\n",
    "    net.add(Conv2D(channels=32, kernel_size=(3, 3), padding=0, activation=\"relu\"))\n",
    "    net.add(Conv2D(channels=32, kernel_size=(3, 3), padding=0, activation=\"relu\"))\n",
    "    net.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    net.add(Dropout(.25))\n",
    "    net.add(Flatten())\n",
    "    net.add(Dense(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.initializer import Xavier\n",
    "\n",
    "# Also known as Glorot\n",
    "net.collect_params().initialize(Xavier(magnitude=2.24), ctx=mx.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon import Trainer\n",
    "\n",
    "trainer = Trainer(net.collect_params(), optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon.contrib import estimator\n",
    "from mxnet.metric import Accuracy\n",
    "from mxnet.gluon.loss import SoftmaxCrossEntropyLoss\n",
    "\n",
    "est = estimator.Estimator(net=net, loss=SoftmaxCrossEntropyLoss(), metrics=Accuracy(), trainer=trainer)\n",
    "est.fit(train_data=train_data, epochs=5, val_data=validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(filename=\"Kimberly recites some shameless self promotion ad.mp3\", autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "cp Kimberly\\ recites\\ some\\ shameless\\ self\\ promotion\\ ad.mp3 data/mp3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "ls -al data/mp3 | head -6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_mp3(None, \"Kimberly recites some shameless self promotion ad.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "ls -al data/wav | head -6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_spectrogram(\"Kimberly recites some shameless self promotion ad.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "ls -al data/spectrograms | head -6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = \"data/spectrograms/Kimberly recites some shameless self promotion ad.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = {\n",
    "    \"spectrogram\": \"data/spectrograms/Kimberly recites some shameless self promotion ad.png\",\n",
    "    \"label\": -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_as_ndarray, _ = transform(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_as_ndarray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_ndarray_batch = mx.ndarray.expand_dims(img_as_ndarray, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_ndarray_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_prediction = net(one_ndarray_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = mx.nd.argmax(raw_prediction, axis=1) \\\n",
    "    .asnumpy() \\\n",
    "    .astype(np.int) \\\n",
    "    .ravel()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voices[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_phrase = input(\"What phrase to pronounce?\")\n",
    "test_voice = input(\"Ivy, Joanna, Joey, Justin, Kendra, Kimberly, Matthew or Salli?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_response = client.synthesize_speech(\n",
    "    OutputFormat=\"mp3\",\n",
    "    Text=test_phrase,\n",
    "    TextType=\"text\",\n",
    "    VoiceId=test_voice\n",
    ")\n",
    "with closing(test_response[\"AudioStream\"]) as stream:\n",
    "    # Write the stream to a bytes buffer in memory\n",
    "    with io.BytesIO() as buffer:\n",
    "        # If we fail, for whatever reason (Eg: AWS is throttling us), we skip the file\n",
    "        try:\n",
    "            buffer.write(stream.read())\n",
    "            buffer.seek(0)\n",
    "            # Finally write the mp3 to disk\n",
    "            with open(\"test.mp3\", \"wb\") as out:\n",
    "                out.write(buffer.read())\n",
    "        except _:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(filename=\"test.mp3\", autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "cp test.mp3 data/mp3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_mp3(None, \"test.mp3\")\n",
    "graph_spectrogram(\"test.wav\")\n",
    "test_row = {\n",
    "    \"spectrogram\": \"data/spectrograms/test.png\",\n",
    "    \"label\": -1\n",
    "}\n",
    "test_img_as_ndarray, _ = transform(test_row)\n",
    "test_raw_prediction = net(mx.ndarray.expand_dims(test_img_as_ndarray, axis=0))\n",
    "test_idx = mx.nd.argmax(test_raw_prediction, axis=1) \\\n",
    "    .asnumpy() \\\n",
    "    .astype(np.int) \\\n",
    "    .ravel()[0]\n",
    "voices[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
